{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEP Python Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you have dropped 4305 rows of duplicate records.\n",
      "   FirstName   LastName                       Email       Phone  \\\n",
      "0    Matthew   Williams  Matthew.Williams@email.com  0532788309   \n",
      "3     Louise  Rodriguez  Louise.Rodriguez@email.com  5539811593   \n",
      "4    Charles      Smith     Charles.Smith@email.com  5233815730   \n",
      "5       Lisa      Jones        Lisa.Jones@email.com  8037591018   \n",
      "6      Greta      Jones       Greta.Jones@email.com  6796258398   \n",
      "7        Ted     Thomas        Ted.Thomas@email.com  3019050866   \n",
      "8    Matthew   Gonzalez  Matthew.Gonzalez@email.com  5622374649   \n",
      "9       Zoey      Smith        Zoey.Smith@email.com  9439505894   \n",
      "10   Charles      Brown     Charles.Brown@email.com  4484721969   \n",
      "11       Ted   Anderson      Ted.Anderson@email.com  0038580112   \n",
      "\n",
      "                Address  \n",
      "0    0532 Williams Lane  \n",
      "3   5539 Rodriguez Lane  \n",
      "4       5233 Smith Lane  \n",
      "5       8037 Jones Lane  \n",
      "6       6796 Jones Lane  \n",
      "7      3019 Thomas Lane  \n",
      "8    5622 Gonzalez Lane  \n",
      "9       9439 Smith Lane  \n",
      "10      4484 Brown Lane  \n",
      "11   0038 Anderson Lane  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_1=pd.read_csv('people_1.txt', sep='\\t', header=0)\n",
    "df_2=pd.read_csv('people_2.txt', sep='\\t', header=0)\n",
    "df = pd.concat([df_1, df_2], ignore_index=True, sort=False).astype(str)\n",
    "\n",
    "# capitalize first name & last name\n",
    "df['FirstName']=df['FirstName'].str.capitalize().apply(lambda x: x.strip())\n",
    "df['LastName']=df['LastName'].str.capitalize().apply(lambda x: x.strip())\n",
    "\n",
    "# remove space on both ends of email address\n",
    "df['Email']=df['Email'].apply(lambda x: x.strip())\n",
    "# erase all '-'s from phone number\n",
    "df['Phone']=df['Phone'].apply(lambda x: x.replace('-','').strip())\n",
    "\n",
    "# erase all 'No.' and '#'\n",
    "df['Address']=df['Address'].apply(lambda x: x.replace('No.','').strip()).apply(lambda x: x.replace('#','').strip())\n",
    "\n",
    "# remove duplicates\n",
    "new_df=df.drop_duplicates()\n",
    "print('you have dropped '+str(len(df)-len(new_df))+' rows of duplicate records.')\n",
    "\n",
    "# show results\n",
    "print(new_df.head(10))\n",
    "\n",
    "#save result to a csv file\n",
    "df.to_csv('people.txt', sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe js_1 has 1249 rows of data\n",
      "dataframe js_2 has 1249 rows of data\n",
      "dataframe js_3 has 1249 rows of data\n",
      "dataframe js_4 has 1249 rows of data\n",
      "dataframe js_5 has 1249 rows of data\n",
      "dataframe js_6 has 1249 rows of data\n",
      "dataframe js_7 has 1249 rows of data\n",
      "dataframe js_8 has 1252 rows of data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "js = pd.read_json('movie.json')\n",
    "\n",
    "# trunk json file evenly into 8 parts\n",
    "trunk_num = 8\n",
    "rows = int(np.floor(len(js)/trunk_num))\n",
    "\n",
    "# automatically name those 8 part with name from js_1 to js_8\n",
    "for i in range(trunk_num-1):\n",
    "    vars()[\"js_\"+str(i+1)]=js.iloc[i*rows:(i+1)*rows]\n",
    "vars()[\"js_\"+str(trunk_num)]=js.iloc[(trunk_num-1)*rows:]\n",
    "\n",
    "# print number of rows from each sub-dataframe\n",
    "for i in range(trunk_num):\n",
    "    print(\"dataframe js_\"+str(i+1)+' has '+str(len(vars()[\"js_\"+str(i+1)]))+' rows of data')\n",
    "# automatically save those into json format\n",
    "for i in range(trunk_num):\n",
    "    vars()[\"js_\"+str(i+1)].to_json(\"js_\"+str(i+1)+'.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a paragraph on what PaaS, SaaS and IaaS are and the differences between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition:\n",
    "#### PaaS: Platform as a service. It provides a platform where you can develop your own applications without having to manage any underlying infrastructure resources. If you want to rapidly rollout modern applications using composable services, but don’t mind the vendor lock-in, choose PaaS.\n",
    "#### SaaS: Software as a service. It gives you access to pre-built business apps without installing anything themselves. If you want ease of use and don’t need much flexibility, choose SaaS.\n",
    "#### IaaS: Infrastructure as a service. It provides virtual servers with all necessary software installed on them so that customers can install their own applications or use an existing application developed by a third-party vendor. If you want maximum control within the cloud, choose IaaS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Cloud Service | IaaS | PaaS | SaaS |\n",
    "| --- | --- | --- | --- |\n",
    "| User | network architect | developer | end user |\n",
    "| Example | AWS EC2, Microsoft Azure | AWS Elastic Beanstalk, Google App Engine | Google Workspace |\n",
    "| Provider Control | infrastructure(network, virtualization, hardware) | infrastructure, platform | infrastructure, platform, software |\n",
    "| User Control | platform(OS, middleware, runtime), software(data, apps) | software | nothing but just using the software |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a paragraph on the differences between ETL and ELT. \n",
    "### Also, list the pros and cons of each in a chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference between ETL (extract, transform, load) and ELT (extract, load, transform)\n",
    "#### 1. ETL transforms data on a separate processing server, while ELT transforms data within the data warehouse itself.\n",
    "#### 2. ETL does not transfer raw data into the data warehouse, while ELT sends raw data directly to the data warehouse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Workflow | ETL | ELT |\n",
    "| --- | --- | --- |\n",
    "| Speed | slow | fast |\n",
    "| Data Lake Compatibility  | no | yes |\n",
    "| Size/Type  | smaller, relational | no limits |\n",
    "| Maturity | over 20 years | new |\n",
    "| Maintance | frequent | low |\n",
    "| Costs | high | low |\n",
    "| Data Volumn | small | large |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5(Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a python script that will calculate/display:\n",
    "### 1. Names, types and sizes of blobs in a certain container\n",
    "### 2. Names and sizes of “folders” in a certain container\n",
    "### 3. connection_string = \"DefaultEndpointsProtocol=https;AccountName=antrablobstorage;AccountKey=ECVP9sDWl64Ubd6w3lGd4d4fbiZuwHWWu1q/KoS2sCR18mwwkSxf1gLC7PvqCT1jWi3IYE87ZQtJYMIztIg3vg==;EndpointSuffix=core.windows.net\"\n",
    "### 4. container_name = \"imagescontainer\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
