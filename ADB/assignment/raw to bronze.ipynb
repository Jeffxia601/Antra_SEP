{"cells":[{"cell_type":"markdown","source":["#1. Connect to data stored in my storage account"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca2372a1-5f6f-406a-bbd0-b458d1005c68"}}},{"cell_type":"code","source":["storage_account_name = \"jeffxia601blob\"\nstorage_account_access_key = \"O2Lk7G1+tMcjKszSnf4ZyJQtGuW7tq//Rxm9hljRBUrjOB58pS7EGmfLAqit2NJvLEY3nNGjyR80+AStZhTCuQ==Y\"\n\n# file_1_location = \"https://jeffxia601blob.blob.core.windows.net/movies/movie_0.json\"\nfile_1_location = \"wasbs://blob_container@jeffxia601blob.blob.core.windows.net/movies/movie_0.json\"\nfile_2_location = \"wasbs://blob_container@jeffxia601blob.blob.core.windows.net/movies/movie_1.json\"\nfile_type = \"json\"\n\nspark.conf.set(\n  \"fs.azure.account.key.\"+storage_account_name+\".blob.core.windows.net\",\n  storage_account_access_key)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2d80bf55-c748-4bb9-8ef9-c5045b72e5b1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### I don't know why it got stuck here. I cannot fix it."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7857187-7666-49d1-9949-0681be65b1dc"}}},{"cell_type":"code","source":["df_1 = spark.read.format(file_type).option(\"inferSchema\", \"true\").load(file_1_location)\ndf_2 = spark.read.format(file_type).option(\"inferSchema\", \"true\").load(file_2_location)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e43fc7b-ffcc-4ce8-bf06-041cc86629e4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4012104938336030&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>df_1 <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>read<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>file_type<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;inferSchema&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;true&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>file_1_location<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> df_2 <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>read<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>file_type<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;inferSchema&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;true&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>file_2_location<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">load</span><span class=\"ansi-blue-fg\">(self, path, format, schema, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    156</span>         self<span class=\"ansi-blue-fg\">.</span>options<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>options<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    157</span>         <span class=\"ansi-green-fg\">if</span> isinstance<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">,</span> str<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 158</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    159</span>         <span class=\"ansi-green-fg\">elif</span> path <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    160</span>             <span class=\"ansi-green-fg\">if</span> type<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">!=</span> list<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    116</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 117</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    119</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    324</span>             value <span class=\"ansi-blue-fg\">=</span> OUTPUT_CONVERTER<span class=\"ansi-blue-fg\">[</span>type<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">(</span>answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    325</span>             <span class=\"ansi-green-fg\">if</span> answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">==</span> REFERENCE_TYPE<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 326</span><span class=\"ansi-red-fg\">                 raise Py4JJavaError(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    328</span>                     format(target_id, &#34;.&#34;, name), value)\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o623.load.\n: shaded.databricks.org.apache.hadoop.fs.azure.AzureException: java.lang.StringIndexOutOfBoundsException: String index out of range: 89\n\tat shaded.databricks.org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.createAzureStorageSession(AzureNativeFileSystemStore.java:1063)\n\tat shaded.databricks.org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.initialize(AzureNativeFileSystemStore.java:512)\n\tat shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem.initialize(NativeAzureFileSystem.java:1383)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:55)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:405)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:356)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:323)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:323)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:236)\n\tat sun.reflect.GeneratedMethodAccessor602.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.StringIndexOutOfBoundsException: String index out of range: 89\n\tat java.lang.String.charAt(String.java:658)\n\tat hadoop_azure_shaded.com.microsoft.azure.storage.core.Base64.decode(Base64.java:82)\n\tat hadoop_azure_shaded.com.microsoft.azure.storage.StorageCredentialsAccountAndKey.&lt;init&gt;(StorageCredentialsAccountAndKey.java:81)\n\tat shaded.databricks.org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.connectUsingConnectionStringCredentials(AzureNativeFileSystemStore.java:903)\n\tat shaded.databricks.org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.createAzureStorageSession(AzureNativeFileSystemStore.java:1048)\n\t... 22 more\n</div>","errorSummary":"shaded.databricks.org.apache.hadoop.fs.azure.AzureException: java.lang.StringIndexOutOfBoundsException: String index out of range: 89","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4012104938336030&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>df_1 <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>read<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>file_type<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;inferSchema&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;true&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>file_1_location<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> df_2 <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>read<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>file_type<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;inferSchema&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;true&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>file_2_location<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">load</span><span class=\"ansi-blue-fg\">(self, path, format, schema, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    156</span>         self<span class=\"ansi-blue-fg\">.</span>options<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>options<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    157</span>         <span class=\"ansi-green-fg\">if</span> isinstance<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">,</span> str<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 158</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    159</span>         <span class=\"ansi-green-fg\">elif</span> path <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    160</span>             <span class=\"ansi-green-fg\">if</span> type<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">!=</span> list<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    116</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 117</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    119</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    324</span>             value <span class=\"ansi-blue-fg\">=</span> OUTPUT_CONVERTER<span class=\"ansi-blue-fg\">[</span>type<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">(</span>answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    325</span>             <span class=\"ansi-green-fg\">if</span> answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">==</span> REFERENCE_TYPE<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 326</span><span class=\"ansi-red-fg\">                 raise Py4JJavaError(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    328</span>                     format(target_id, &#34;.&#34;, name), value)\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o623.load.\n: shaded.databricks.org.apache.hadoop.fs.azure.AzureException: java.lang.StringIndexOutOfBoundsException: String index out of range: 89\n\tat shaded.databricks.org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.createAzureStorageSession(AzureNativeFileSystemStore.java:1063)\n\tat shaded.databricks.org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.initialize(AzureNativeFileSystemStore.java:512)\n\tat shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem.initialize(NativeAzureFileSystem.java:1383)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:55)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:405)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:356)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:323)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:323)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:236)\n\tat sun.reflect.GeneratedMethodAccessor602.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.StringIndexOutOfBoundsException: String index out of range: 89\n\tat java.lang.String.charAt(String.java:658)\n\tat hadoop_azure_shaded.com.microsoft.azure.storage.core.Base64.decode(Base64.java:82)\n\tat hadoop_azure_shaded.com.microsoft.azure.storage.StorageCredentialsAccountAndKey.&lt;init&gt;(StorageCredentialsAccountAndKey.java:81)\n\tat shaded.databricks.org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.connectUsingConnectionStringCredentials(AzureNativeFileSystemStore.java:903)\n\tat shaded.databricks.org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.createAzureStorageSession(AzureNativeFileSystemStore.java:1048)\n\t... 22 more\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# display(df_1.select(\"EXAMPLE_COLUMN\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"67fbea4f-f6b3-4e72-b2a6-c186c6aac66a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# df_1.createOrReplaceTempView(\"TEMP_VIEW_NAME\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"abec7474-f4c6-4270-bb59-bab8bfdd726d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- SELECT EXAMPLE_GROUP, SUM(EXAMPLE_AGG) FROM YOUR_TEMP_VIEW_NAME GROUP BY EXAMPLE_GROUP"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a350498-5055-4cfe-84de-32aca6a50b9f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# 2. Concatenate 8 json files"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6fa3c0d6-9782-460f-80e5-4d797a1a1129"}}},{"cell_type":"code","source":["from functools import reduce\n\ndf=reduce(lambda x,y:x.union(y), [df_1,df_2,df_3,df_4,df_5,df_6,df_7,df_8])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a69c21e7-e074-4ec1-ab41-9c51f8e7fc4e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# 3. Change data from raw to bronze"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66523657-a194-43d5-b814-2b21d097dab0"}}},{"cell_type":"code","source":["# raw ingestion"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eb4541fa-1074-4ee2-af3e-7e8b62d35883"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"raw to bronze","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":4012104938336007}},"nbformat":4,"nbformat_minor":0}
